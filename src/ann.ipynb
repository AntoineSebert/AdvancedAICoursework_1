{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 400\n",
    "output_nodes = 10\n",
    "\n",
    "# initial values\n",
    "learning_rate = 0.2\n",
    "batch_size = 40\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "\t\"\"\"Artificial Neural Network classifier.\n",
    "\n",
    "\tParameters\n",
    "\t------------\n",
    "\tlr : float\n",
    "\t\tLearning rate (between 0.0 and 1.0)\n",
    "\tep : int\n",
    "\t\tNumber of epochs for training the network towards achieving convergence\n",
    "\tbatch_size : int\n",
    "\t\tSize of the training batch to be used when calculating the gradient descent.\n",
    "\t\tbatch_size = 0 standard gradient descent\n",
    "\t\tbatch_size > 0 stochastic gradient descent\n",
    "\n",
    "\tinodes : int\n",
    "\t\tNumber of input nodes which is normally the number of features in an instance.\n",
    "\thnodes : int\n",
    "\t\tNumber of hidden nodes in the net.\n",
    "\tonodes : int\n",
    "\t\tNumber of output nodes in the net.\n",
    "\n",
    "\n",
    "\tAttributes\n",
    "\t-----------\n",
    "\twih : 2d-array\n",
    "\t\tInput2Hidden node weights after fitting\n",
    "\twho : 2d-array\n",
    "\t\tHidden2Output node weights after fitting\n",
    "\tE : list\n",
    "\t\tSum-of-squares error value in each epoch.\n",
    "\n",
    "\tResults : list\n",
    "\t\tTarget and predicted class labels for the test data.\n",
    "\n",
    "\tFunctions\n",
    "\t---------\n",
    "\tactivation_function : float (between 1 and -1)\n",
    "\t\timplments the sigmoid function which squashes the node input\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, inputnodes = 784, hiddennodes = 200, outputnodes = 10, learningrate = 0.2, batch_size = 40, epochs = 100):\n",
    "\t\tself.inodes = inputnodes\n",
    "\t\tself.hnodes = hiddennodes\n",
    "\t\tself.onodes = outputnodes\n",
    "\n",
    "\t\t#link weight matrices, wih (input to hidden) and who (hidden to output)\n",
    "\t\t#a weight on link from node i to node j is w_ij\n",
    "\n",
    "\t\t#Draw random samples from a normal (Gaussian) distribution centered around 0.\n",
    "\t\t#numpy.random.normal(loc to centre gaussian=0.0, scale=1, size=dimensions of the array we want)\n",
    "\t\t#scale is usually set to the standard deviation which is related to the number of incoming links i.e.\n",
    "\t\t#1/sqrt(num of incoming inputs). we use pow to raise it to the power of -0.5.\n",
    "\t\t#We have set 0 as the centre of the guassian dist.\n",
    "\t\t# size is set to the dimensions of the number of hnodes, inodes and onodes\n",
    "\t\tself.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "\t\tself.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "\t\t#set the learning rate\n",
    "\t\tself.lr = learningrate\n",
    "\n",
    "\t\t#set the batch size\n",
    "\t\tself.bs = batch_size\n",
    "\n",
    "\t\t#set the number of epochs\n",
    "\t\tself.ep = epochs\n",
    "\n",
    "\t\t#store errors at each epoch\n",
    "\t\tself.E = []\n",
    "\n",
    "\t\t#store results from testing the model\n",
    "\t\t#keep track of the network performance on each test instance\n",
    "\t\tself.results = []\n",
    "\n",
    "\t\t#define the activation function here\n",
    "\t\t#specify the sigmoid squashing function. Here expit() provides the sigmoid function.\n",
    "\t\t#lambda is a short cut function which is executed there and then with no def (i.e. like an anonymous function)\n",
    "\t\tself.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "\t\tpass\n",
    "\n",
    "\tdef batch_input(self, input_list):\n",
    "\t\t\"\"\"Yield consecutive batches of the specified size from the input list.\"\"\"\n",
    "\t\tfor i in range(0, len(input_list), self.bs):\n",
    "\t\t\tyield input_list[i:i + self.bs]\n",
    "\n",
    "\t#train the neural net\n",
    "\t#note the first part is very similar to the query function because they both require the forward pass\n",
    "\tdef train(self, train_inputs):\n",
    "\t\t\"\"\"Training the neural net.\n",
    "\t\t\tThis includes the forward pass ; error computation;\n",
    "\t\t\tbackprop of the error ; calculation of gradients and updating the weights.\n",
    "\n",
    "\t\t\tParameters\n",
    "\t\t\t----------\n",
    "\t\t\ttrain_inputs : {array-like}, shape = [n_instances, n_features]\n",
    "\t\t\tTraining vectors, where n_instances is the number of training instances and\n",
    "\t\t\tn_features is the number of features.\n",
    "\t\t\tNote this contains all features including the class feature which is in first position\n",
    "\n",
    "\t\t\tReturns\n",
    "\t\t\t-------\n",
    "\t\t\tself : object\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tfor e in range(self.ep):\n",
    "\t\t\tprint(\"Training epoch#: \", e)\n",
    "\t\t\tsum_error = 0.0\n",
    "\t\t\tfor batch in self.batch_input(train_inputs):\n",
    "\t\t\t\t#creating variables to store the gradients\n",
    "\t\t\t\tdelta_who = 0\n",
    "\t\t\t\tdelta_wih = 0\n",
    "\n",
    "\t\t\t\t# iterate through the inputs sent in\n",
    "\t\t\t\tfor instance in batch:\n",
    "\t\t\t\t\t# split it by the commas\n",
    "\t\t\t\t\tall_values = instance.split(',')\n",
    "\t\t\t\t\t# scale and shift the inputs to address the problem of diminishing weights due to multiplying by zero\n",
    "\t\t\t\t\t# divide the raw inputs which are in the range 0-255 by 255 will bring them into the range 0-1\n",
    "\t\t\t\t\t# multiply by 0.99 to bring them into the range 0.0 - 0.99.\n",
    "\t\t\t\t\t# add 0.01 to shift them up to the desired range 0.01 - 1.\n",
    "\t\t\t\t\tinputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\t\t\t\t\t#create the target output values for each instance so that we can use it with the neural net\n",
    "\t\t\t\t\t#note we need 10 nodes where each represents one of the digits\n",
    "\t\t\t\t\ttargets = numpy.zeros(output_nodes) + 0.01 #all initialised to 0.01\n",
    "\t\t\t\t\t#all_value[0] has the target class label for this instance\n",
    "\t\t\t\t\ttargets[int(all_values[0])] = 0.99\n",
    "\n",
    "\t\t\t\t\t#convert  inputs list to 2d array\n",
    "\t\t\t\t\tinputs = numpy.array(inputs,  ndmin = 2).T\n",
    "\t\t\t\t\ttargets = numpy.array(targets, ndmin = 2).T\n",
    "\n",
    "\t\t\t\t\t#calculate signals into hidden layer\n",
    "\t\t\t\t\thidden_inputs = numpy.dot(self.wih, inputs)\n",
    "\t\t\t\t\t#calculate the signals emerging from the hidden layer\n",
    "\t\t\t\t\thidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "\t\t\t\t\t#calculate signals into final output layer\n",
    "\t\t\t\t\tfinal_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "\t\t\t\t\t#calculate the signals emerging from final output layer\n",
    "\t\t\t\t\tfinal_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "\t\t\t\t\t#to calculate the error we need to compute the element wise diff between target and actual\n",
    "\t\t\t\t\toutput_errors = targets - final_outputs\n",
    "\t\t\t\t\t#Next distribute the error to the hidden layer such that hidden layer error\n",
    "\t\t\t\t\t#is the output_errors, split by weights, recombined at hidden nodes\n",
    "\t\t\t\t\thidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "\n",
    "\t\t\t\t\t## for each instance accumilate the gradients from each instance\n",
    "\t\t\t\t\t## delta_who are the gradients between hidden and output weights\n",
    "\t\t\t\t\t## delta_wih are the gradients between input and hidden weights\n",
    "\t\t\t\t\tdelta_who += numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "\t\t\t\t\tdelta_wih += numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "\n",
    "\t\t\t\t\tsum_error += numpy.dot(output_errors.T, output_errors)#this is the sum of squared error accumilated over each batced instance\n",
    "\n",
    "\t\t\t\tpass #instance\n",
    "\n",
    "\t\t\t\t# update the weights by multiplying the gradient with the learning rate\n",
    "\t\t\t\t# note that the deltas are divided by batch size to obtain the average gradient according to the given batch\n",
    "\t\t\t\t# obviously if batch size = 1 then we dont need to bother with an average\n",
    "\t\t\t\tself.who += self.lr * (delta_who / self.bs)\n",
    "\t\t\t\tself.wih += self.lr * (delta_wih / self.bs)\n",
    "\t\t\tpass # batch\n",
    "\t\t\tself.E.append(numpy.asfarray(sum_error).flatten())\n",
    "\t\t\tprint(\"errors (SSE): \", self.E[-1])\n",
    "\t\tpass # epoch\n",
    "\n",
    "\t#query the neural net\n",
    "\tdef query(self, inputs_list):\n",
    "\t\t#convert inputs_list to a 2d array\n",
    "\t\t#print(numpy.matrix(inputs_list))\n",
    "\t\t#inputs_list [[ 1.   0.5 -1.5]]\n",
    "\t\tinputs = numpy.array(inputs_list, ndmin = 2).T\n",
    "\t\t#once converted it appears as follows\n",
    "\t\t#[[ 1. ]\n",
    "\t\t# [ 0.5]\n",
    "\t\t# [-1.5]]\n",
    "\t\t#print(numpy.matrix(inputs))\n",
    "\n",
    "\t\t#propogate input into hidden layer. This is the start of the forward pass\n",
    "\t\thidden_inputs = numpy.dot(self.wih, inputs)\n",
    "\n",
    "\t\t#squash the content in the hidden node using the sigmoid function (value between 1, -1)\n",
    "\t\thidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "\t\t#propagate into output layer and the apply the squashing sigmoid function\n",
    "\t\tfinal_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "\n",
    "\t\tfinal_outputs = self.activation_function(final_inputs)\n",
    "\t\treturn final_outputs\n",
    "\n",
    "\t#iterate through all the test data to calculate model accuracy\n",
    "\tdef test(self, test_inputs):\n",
    "\t\tself.results = []\n",
    "\n",
    "\t\t#go through each test instances\n",
    "\t\tfor instance in test_inputs:\n",
    "\t\t\tall_values = instance.split(',') # extract the input feature values for the instance\n",
    "\n",
    "\t\t\ttarget_label = int(all_values[0]) # get the target class for the instance\n",
    "\n",
    "\t\t\t#scale and shift the inputs this is to make sure values dont lead to zero when multiplied with weights\n",
    "\t\t\tinputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "\t\t\t#query the network with test inputs\n",
    "\t\t\t#note this returns 10 output values ; of which the index of the highest value\n",
    "\t\t\t# is the networks predicted class label\n",
    "\t\t\toutputs = self.query(inputs)\n",
    "\n",
    "\t\t\t#get the index of the highest output node as this corresponds to the predicted class\n",
    "\t\t\tpredict_label = numpy.argmax(outputs) #this is the class predicted by the ANN\n",
    "\n",
    "\t\t\tself.results.append([predict_label, target_label])\n",
    "\t\t\t#compute network error\n",
    "\t\t\t#if (predict_label == target_label):\n",
    "\t\t\t#\tself.results.append(1)\n",
    "\t\t\t#else:\n",
    "\t\t\t#\tself.results.append(0)\n",
    "\t\t\tpass\n",
    "\t\tpass\n",
    "\t\tself.results = numpy.asfarray(self.results) # flatten results to avoid nested arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size:  60000\n",
      "test set size:  10000\n"
     ]
    }
   ],
   "source": [
    "mnist_train_file = open(\"../datasets/mnist_train.csv\", 'r')\n",
    "mnist_train_list = mnist_train_file.readlines() \n",
    "mnist_train_file.close() \n",
    "print(\"train set size: \", len(mnist_train_list))\n",
    "\n",
    "mnist_test_file = open(\"../datasets/mnist_test.csv\", 'r')\n",
    "mnist_test_list = mnist_test_file.readlines()\n",
    "mnist_test_file.close()\n",
    "print(\"test set size: \", len(mnist_test_list))\n",
    "\n",
    "# quick run\n",
    "#mnist_train_list = numpy.random.choice(mnist_train_list, 1000, replace = False)\n",
    "#mnist_test_list = numpy.random.choice(mnist_test_list, 1000, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /=: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-10ef212ff194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmnist_train_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpixel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mpixel\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_train_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /=: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "print(mnist_train_list[0])\n",
    "for entry in mnist_train_list:\n",
    "    for pixel in entry:\n",
    "        pixel /= 255\n",
    "print(mnist_train_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs\n",
    "\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs :  1\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [688.9232462]\n",
      "Number of epochs :  10\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [795.56803193]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [307.34538554]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [245.38153364]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [214.00881938]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [193.99647263]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [179.59215732]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [168.41552912]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [159.31073204]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [151.64285044]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [145.02702898]\n",
      "Number of epochs :  100\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [758.13877082]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [292.53420884]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [234.2113082]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [205.77270801]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [187.60357501]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [174.34016438]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [163.87270802]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [155.21251096]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [147.82284563]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [141.37797679]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [135.66424625]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [130.53387931]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [125.88079142]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [121.62666353]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [117.71224175]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [114.09153623]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [110.72782602]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [107.59092122]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [104.65534893]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [101.89920659]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [99.30346469]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [96.85154233]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [94.52902974]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [92.32347314]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [90.22416612]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [88.22191535]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [86.30877847]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [84.47779952]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [82.7227772]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [81.03809117]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [79.41859042]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [77.85953175]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [76.35654971]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [74.90564159]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [73.50315713]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [72.14578838]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [70.83055927]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [69.55481586]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [68.31621693]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [67.11272221]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [65.94257273]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [64.80425811]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [63.69646909]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [62.61804019]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [61.56789213]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [60.54498459]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [59.54828583]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [58.57676018]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [57.62936941]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [56.70508238]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [55.80288736]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [54.92180321]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [54.06088761]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [53.2192418]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [52.39601262]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [51.59039313]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [50.80162328]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [50.02899218]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [49.27184305]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [48.52958098]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [47.80168236]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [47.08770321]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [46.38728269]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [45.7001382]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [45.02605061]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [44.3648413]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [43.71634569]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [43.08038895]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [42.45676862]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [41.84524617]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [41.24554713]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [40.65736734]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [40.08038276]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [39.51426005]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [38.95866635]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [38.41327724]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [37.87778241]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [37.35188917]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [36.83532412]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [36.32783329]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [35.82918124]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [35.33914949]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [34.8575345]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [34.38414569]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [33.9188034]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [33.46133706]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [33.01158365]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [32.5693864]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [32.13459375]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [31.70705853]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [31.28663743]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [30.87319057]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [30.46658121]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [30.06667566]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [29.67334312]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [29.28645566]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [28.90588823]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [28.53151867]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [28.16322768]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [27.80089884]\n",
      "Number of epochs :  200\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [670.08905267]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [299.38157061]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [242.7400788]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [212.27990228]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [192.41602831]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [178.08690133]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [166.98707738]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [157.96308247]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [150.36345254]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [143.78799513]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [137.97930808]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [132.76682642]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [128.03416119]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [123.69921962]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [119.70205032]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [115.99733911]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [112.54963051]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [109.33015795]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [106.31472032]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [103.4823512]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [100.81460714]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [98.29526384]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [95.91018611]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [93.64718816]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [91.49580297]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [89.44697805]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [87.49276287]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [85.62604541]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [83.84036131]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [82.12977233]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [80.4887996]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [78.91239561]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [77.39593909]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [75.93523614]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [74.52651398]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [73.16639914]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [71.85188153]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [70.58027279]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [69.34916958]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [68.15642725]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [67.00014107]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [65.87862529]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [64.79037959]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [63.73404001]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [62.70832094]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [61.7119615]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [60.74368845]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [59.80220119]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [58.88617685]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [57.99428882]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [57.12523114]\n",
      "Training epoch#:  51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [56.27774279]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [55.4506281]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [54.64277164]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [53.85314688]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [53.080819]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [52.32494238]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [51.58475394]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [50.85956368]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [50.14874389]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [49.45171855]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [48.76795396]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [48.09695123]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [47.43824096]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [46.79137995]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [46.15594969]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [45.5315562]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [44.91783106]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [44.31443307]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [43.72105052]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [43.13740347]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [42.56324558]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [41.99836495]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [41.44258316]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [40.89575225]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [40.35774916]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [39.82846846]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [39.30781402]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [38.79569094]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [38.29199891]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [37.79662772]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [37.30945527]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [36.8303478]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [36.35916171]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [35.89574639]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [35.43994735]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [34.99160902]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [34.55057707]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [34.11670001]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [33.68983005]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [33.26982333]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [32.85653976]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [32.4498425]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [32.0495974]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [31.65567236]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [31.26793682]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [30.88626135]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [30.51051747]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [30.1405775]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [29.77631457]\n",
      "Training epoch#:  100\n",
      "errors (SSE):  [29.41760282]\n",
      "Training epoch#:  101\n",
      "errors (SSE):  [29.0643175]\n",
      "Training epoch#:  102\n",
      "errors (SSE):  [28.71633531]\n",
      "Training epoch#:  103\n",
      "errors (SSE):  [28.37353467]\n",
      "Training epoch#:  104\n",
      "errors (SSE):  [28.03579613]\n",
      "Training epoch#:  105\n",
      "errors (SSE):  [27.70300275]\n",
      "Training epoch#:  106\n",
      "errors (SSE):  [27.37504062]\n",
      "Training epoch#:  107\n",
      "errors (SSE):  [27.05179936]\n",
      "Training epoch#:  108\n",
      "errors (SSE):  [26.73317274]\n",
      "Training epoch#:  109\n",
      "errors (SSE):  [26.41905933]\n",
      "Training epoch#:  110\n",
      "errors (SSE):  [26.10936308]\n",
      "Training epoch#:  111\n",
      "errors (SSE):  [25.80399408]\n",
      "Training epoch#:  112\n",
      "errors (SSE):  [25.50286903]\n",
      "Training epoch#:  113\n",
      "errors (SSE):  [25.20591184]\n",
      "Training epoch#:  114\n",
      "errors (SSE):  [24.91305391]\n",
      "Training epoch#:  115\n",
      "errors (SSE):  [24.62423425]\n",
      "Training epoch#:  116\n",
      "errors (SSE):  [24.3393993]\n",
      "Training epoch#:  117\n",
      "errors (SSE):  [24.05850245]\n",
      "Training epoch#:  118\n",
      "errors (SSE):  [23.78150317]\n",
      "Training epoch#:  119\n",
      "errors (SSE):  [23.50836594]\n",
      "Training epoch#:  120\n",
      "errors (SSE):  [23.23905878]\n",
      "Training epoch#:  121\n",
      "errors (SSE):  [22.97355179]\n",
      "Training epoch#:  122\n",
      "errors (SSE):  [22.71181552]\n",
      "Training epoch#:  123\n",
      "errors (SSE):  [22.45381957]\n",
      "Training epoch#:  124\n",
      "errors (SSE):  [22.1995313]\n",
      "Training epoch#:  125\n",
      "errors (SSE):  [21.94891488]\n",
      "Training epoch#:  126\n",
      "errors (SSE):  [21.7019307]\n",
      "Training epoch#:  127\n",
      "errors (SSE):  [21.45853509]\n",
      "Training epoch#:  128\n",
      "errors (SSE):  [21.21868037]\n",
      "Training epoch#:  129\n",
      "errors (SSE):  [20.9823152]\n",
      "Training epoch#:  130\n",
      "errors (SSE):  [20.74938509]\n",
      "Training epoch#:  131\n",
      "errors (SSE):  [20.51983301]\n",
      "Training epoch#:  132\n",
      "errors (SSE):  [20.29360012]\n",
      "Training epoch#:  133\n",
      "errors (SSE):  [20.07062649]\n",
      "Training epoch#:  134\n",
      "errors (SSE):  [19.85085169]\n",
      "Training epoch#:  135\n",
      "errors (SSE):  [19.63421543]\n",
      "Training epoch#:  136\n",
      "errors (SSE):  [19.42065805]\n",
      "Training epoch#:  137\n",
      "errors (SSE):  [19.21012089]\n",
      "Training epoch#:  138\n",
      "errors (SSE):  [19.00254665]\n",
      "Training epoch#:  139\n",
      "errors (SSE):  [18.79787958]\n",
      "Training epoch#:  140\n",
      "errors (SSE):  [18.59606563]\n",
      "Training epoch#:  141\n",
      "errors (SSE):  [18.39705256]\n",
      "Training epoch#:  142\n",
      "errors (SSE):  [18.20078992]\n",
      "Training epoch#:  143\n",
      "errors (SSE):  [18.0072291]\n",
      "Training epoch#:  144\n",
      "errors (SSE):  [17.81632325]\n",
      "Training epoch#:  145\n",
      "errors (SSE):  [17.62802721]\n",
      "Training epoch#:  146\n",
      "errors (SSE):  [17.44229748]\n",
      "Training epoch#:  147\n",
      "errors (SSE):  [17.25909204]\n",
      "Training epoch#:  148\n",
      "errors (SSE):  [17.07837034]\n",
      "Training epoch#:  149\n",
      "errors (SSE):  [16.90009317]\n",
      "Training epoch#:  150\n",
      "errors (SSE):  [16.72422254]\n",
      "Training epoch#:  151\n",
      "errors (SSE):  [16.55072164]\n",
      "Training epoch#:  152\n",
      "errors (SSE):  [16.37955471]\n",
      "Training epoch#:  153\n",
      "errors (SSE):  [16.210687]\n",
      "Training epoch#:  154\n",
      "errors (SSE):  [16.04408465]\n",
      "Training epoch#:  155\n",
      "errors (SSE):  [15.87971464]\n",
      "Training epoch#:  156\n",
      "errors (SSE):  [15.71754476]\n",
      "Training epoch#:  157\n",
      "errors (SSE):  [15.55754349]\n",
      "Training epoch#:  158\n",
      "errors (SSE):  [15.39968]\n",
      "Training epoch#:  159\n",
      "errors (SSE):  [15.24392409]\n",
      "Training epoch#:  160\n",
      "errors (SSE):  [15.09024615]\n",
      "Training epoch#:  161\n",
      "errors (SSE):  [14.9386171]\n",
      "Training epoch#:  162\n",
      "errors (SSE):  [14.78900839]\n",
      "Training epoch#:  163\n",
      "errors (SSE):  [14.64139196]\n",
      "Training epoch#:  164\n",
      "errors (SSE):  [14.49574021]\n",
      "Training epoch#:  165\n",
      "errors (SSE):  [14.35202596]\n",
      "Training epoch#:  166\n",
      "errors (SSE):  [14.21022247]\n",
      "Training epoch#:  167\n",
      "errors (SSE):  [14.0703034]\n",
      "Training epoch#:  168\n",
      "errors (SSE):  [13.93224278]\n",
      "Training epoch#:  169\n",
      "errors (SSE):  [13.79601502]\n",
      "Training epoch#:  170\n",
      "errors (SSE):  [13.66159486]\n",
      "Training epoch#:  171\n",
      "errors (SSE):  [13.52895742]\n",
      "Training epoch#:  172\n",
      "errors (SSE):  [13.39807813]\n",
      "Training epoch#:  173\n",
      "errors (SSE):  [13.26893276]\n",
      "Training epoch#:  174\n",
      "errors (SSE):  [13.14149736]\n",
      "Training epoch#:  175\n",
      "errors (SSE):  [13.01574834]\n",
      "Training epoch#:  176\n",
      "errors (SSE):  [12.89166236]\n",
      "Training epoch#:  177\n",
      "errors (SSE):  [12.76921641]\n",
      "Training epoch#:  178\n",
      "errors (SSE):  [12.64838774]\n",
      "Training epoch#:  179\n",
      "errors (SSE):  [12.52915391]\n",
      "Training epoch#:  180\n",
      "errors (SSE):  [12.41149275]\n",
      "Training epoch#:  181\n",
      "errors (SSE):  [12.29538233]\n",
      "Training epoch#:  182\n",
      "errors (SSE):  [12.18080105]\n",
      "Training epoch#:  183\n",
      "errors (SSE):  [12.06772751]\n",
      "Training epoch#:  184\n",
      "errors (SSE):  [11.95614064]\n",
      "Training epoch#:  185\n",
      "errors (SSE):  [11.84601956]\n",
      "Training epoch#:  186\n",
      "errors (SSE):  [11.73734371]\n",
      "Training epoch#:  187\n",
      "errors (SSE):  [11.63009273]\n",
      "Training epoch#:  188\n",
      "errors (SSE):  [11.52424654]\n",
      "Training epoch#:  189\n",
      "errors (SSE):  [11.4197853]\n",
      "Training epoch#:  190\n",
      "errors (SSE):  [11.31668942]\n",
      "Training epoch#:  191\n",
      "errors (SSE):  [11.21493954]\n",
      "Training epoch#:  192\n",
      "errors (SSE):  [11.11451657]\n",
      "Training epoch#:  193\n",
      "errors (SSE):  [11.01540162]\n",
      "Training epoch#:  194\n",
      "errors (SSE):  [10.91757606]\n",
      "Training epoch#:  195\n",
      "errors (SSE):  [10.82102151]\n",
      "Training epoch#:  196\n",
      "errors (SSE):  [10.72571978]\n",
      "Training epoch#:  197\n",
      "errors (SSE):  [10.63165295]\n",
      "Training epoch#:  198\n",
      "errors (SSE):  [10.53880331]\n",
      "Training epoch#:  199\n",
      "errors (SSE):  [10.44715338]\n",
      "Number of epochs :  300\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [653.72630992]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [282.4643152]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [229.8360244]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [203.2265526]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [185.76711384]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [172.82771529]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [162.52349258]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [153.94580089]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [146.59383462]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [140.15988841]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [134.43918021]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [129.28783845]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [124.60092147]\n",
      "Training epoch#:  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [120.29971444]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [116.32390864]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [112.62665737]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [109.1714737]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [105.93029813]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [102.88208478]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [100.01126328]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [97.3058116]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [94.75530221]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [92.34953758]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [90.07804615]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [87.93022936]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [85.89576097]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [83.96493538]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [82.12884578]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [80.37941085]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [78.70932166]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [77.11197046]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [75.5813894]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [74.11220151]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [72.69957635]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [71.3391845]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [70.02714982]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [68.7600014]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [67.53462797]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [66.34823648]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [65.19831566]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [64.08260421]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [62.99906312]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [61.94585135]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [60.92130428]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [59.92391451]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [58.95231446]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [58.00526067]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [57.08161958]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [56.18035453]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [55.30051404]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [54.44122122]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [53.60166421]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [52.78108762]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [51.97878496]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [51.19409179]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [50.42637978]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [49.67505138]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [48.9395353]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [48.2192827]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [47.51376436]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [46.82246893]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [46.14490271]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [45.48059113]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [44.82908217]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [44.1899515]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [43.56280873]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [42.94730349]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [42.34312971]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [41.75002656]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [41.16777509]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [40.59619068]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [40.03511249]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [39.48439196]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [38.94388226]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [38.41343021]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [37.8928713]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [37.38202769]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [36.88070854]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [36.38871189]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [35.90582737]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [35.43183912]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [34.96652858]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [34.509677]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [34.06106749]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [33.62048671]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [33.18772611]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [32.76258287]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [32.34486059]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [31.9343696]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [31.53092721]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [31.13435768]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [30.74449214]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [30.36116838]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [29.98423054]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [29.61352884]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [29.24891923]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [28.89026305]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [28.53742673]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [28.1902815]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [27.84870307]\n",
      "Training epoch#:  100\n",
      "errors (SSE):  [27.51257142]\n",
      "Training epoch#:  101\n",
      "errors (SSE):  [27.18177057]\n",
      "Training epoch#:  102\n",
      "errors (SSE):  [26.85618834]\n",
      "Training epoch#:  103\n",
      "errors (SSE):  [26.53571623]\n",
      "Training epoch#:  104\n",
      "errors (SSE):  [26.2202492]\n",
      "Training epoch#:  105\n",
      "errors (SSE):  [25.90968551]\n",
      "Training epoch#:  106\n",
      "errors (SSE):  [25.60392663]\n",
      "Training epoch#:  107\n",
      "errors (SSE):  [25.30287707]\n",
      "Training epoch#:  108\n",
      "errors (SSE):  [25.0064443]\n",
      "Training epoch#:  109\n",
      "errors (SSE):  [24.71453861]\n",
      "Training epoch#:  110\n",
      "errors (SSE):  [24.42707301]\n",
      "Training epoch#:  111\n",
      "errors (SSE):  [24.1439632]\n",
      "Training epoch#:  112\n",
      "errors (SSE):  [23.86512743]\n",
      "Training epoch#:  113\n",
      "errors (SSE):  [23.59048647]\n",
      "Training epoch#:  114\n",
      "errors (SSE):  [23.31996352]\n",
      "Training epoch#:  115\n",
      "errors (SSE):  [23.05348418]\n",
      "Training epoch#:  116\n",
      "errors (SSE):  [22.79097639]\n",
      "Training epoch#:  117\n",
      "errors (SSE):  [22.53237032]\n",
      "Training epoch#:  118\n",
      "errors (SSE):  [22.27759837]\n",
      "Training epoch#:  119\n",
      "errors (SSE):  [22.02659505]\n",
      "Training epoch#:  120\n",
      "errors (SSE):  [21.77929692]\n",
      "Training epoch#:  121\n",
      "errors (SSE):  [21.53564245]\n",
      "Training epoch#:  122\n",
      "errors (SSE):  [21.29557196]\n",
      "Training epoch#:  123\n",
      "errors (SSE):  [21.05902744]\n",
      "Training epoch#:  124\n",
      "errors (SSE):  [20.82595246]\n",
      "Training epoch#:  125\n",
      "errors (SSE):  [20.59629199]\n",
      "Training epoch#:  126\n",
      "errors (SSE):  [20.36999225]\n",
      "Training epoch#:  127\n",
      "errors (SSE):  [20.14700059]\n",
      "Training epoch#:  128\n",
      "errors (SSE):  [19.9272653]\n",
      "Training epoch#:  129\n",
      "errors (SSE):  [19.71073552]\n",
      "Training epoch#:  130\n",
      "errors (SSE):  [19.49736109]\n",
      "Training epoch#:  131\n",
      "errors (SSE):  [19.28709244]\n",
      "Training epoch#:  132\n",
      "errors (SSE):  [19.07988052]\n",
      "Training epoch#:  133\n",
      "errors (SSE):  [18.87567675]\n",
      "Training epoch#:  134\n",
      "errors (SSE):  [18.67443295]\n",
      "Training epoch#:  135\n",
      "errors (SSE):  [18.47610132]\n",
      "Training epoch#:  136\n",
      "errors (SSE):  [18.28063446]\n",
      "Training epoch#:  137\n",
      "errors (SSE):  [18.08798534]\n",
      "Training epoch#:  138\n",
      "errors (SSE):  [17.89810737]\n",
      "Training epoch#:  139\n",
      "errors (SSE):  [17.71095439]\n",
      "Training epoch#:  140\n",
      "errors (SSE):  [17.52648076]\n",
      "Training epoch#:  141\n",
      "errors (SSE):  [17.34464134]\n",
      "Training epoch#:  142\n",
      "errors (SSE):  [17.16539158]\n",
      "Training epoch#:  143\n",
      "errors (SSE):  [16.98868754]\n",
      "Training epoch#:  144\n",
      "errors (SSE):  [16.81448592]\n",
      "Training epoch#:  145\n",
      "errors (SSE):  [16.64274412]\n",
      "Training epoch#:  146\n",
      "errors (SSE):  [16.47342023]\n",
      "Training epoch#:  147\n",
      "errors (SSE):  [16.30647307]\n",
      "Training epoch#:  148\n",
      "errors (SSE):  [16.14186221]\n",
      "Training epoch#:  149\n",
      "errors (SSE):  [15.97954795]\n",
      "Training epoch#:  150\n",
      "errors (SSE):  [15.81949134]\n",
      "Training epoch#:  151\n",
      "errors (SSE):  [15.6616542]\n",
      "Training epoch#:  152\n",
      "errors (SSE):  [15.50599906]\n",
      "Training epoch#:  153\n",
      "errors (SSE):  [15.35248918]\n",
      "Training epoch#:  154\n",
      "errors (SSE):  [15.20108856]\n",
      "Training epoch#:  155\n",
      "errors (SSE):  [15.05176189]\n",
      "Training epoch#:  156\n",
      "errors (SSE):  [14.90447455]\n",
      "Training epoch#:  157\n",
      "errors (SSE):  [14.75919259]\n",
      "Training epoch#:  158\n",
      "errors (SSE):  [14.61588275]\n",
      "Training epoch#:  159\n",
      "errors (SSE):  [14.47451238]\n",
      "Training epoch#:  160\n",
      "errors (SSE):  [14.33504948]\n",
      "Training epoch#:  161\n",
      "errors (SSE):  [14.19746268]\n",
      "Training epoch#:  162\n",
      "errors (SSE):  [14.06172121]\n",
      "Training epoch#:  163\n",
      "errors (SSE):  [13.92779488]\n",
      "Training epoch#:  164\n",
      "errors (SSE):  [13.79565412]\n",
      "Training epoch#:  165\n",
      "errors (SSE):  [13.6652699]\n",
      "Training epoch#:  166\n",
      "errors (SSE):  [13.53661376]\n",
      "Training epoch#:  167\n",
      "errors (SSE):  [13.40965781]\n",
      "Training epoch#:  168\n",
      "errors (SSE):  [13.28437469]\n",
      "Training epoch#:  169\n",
      "errors (SSE):  [13.16073758]\n",
      "Training epoch#:  170\n",
      "errors (SSE):  [13.03872018]\n",
      "Training epoch#:  171\n",
      "errors (SSE):  [12.91829671]\n",
      "Training epoch#:  172\n",
      "errors (SSE):  [12.79944189]\n",
      "Training epoch#:  173\n",
      "errors (SSE):  [12.68213094]\n",
      "Training epoch#:  174\n",
      "errors (SSE):  [12.56633958]\n",
      "Training epoch#:  175\n",
      "errors (SSE):  [12.452044]\n",
      "Training epoch#:  176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [12.33922084]\n",
      "Training epoch#:  177\n",
      "errors (SSE):  [12.22784724]\n",
      "Training epoch#:  178\n",
      "errors (SSE):  [12.11790075]\n",
      "Training epoch#:  179\n",
      "errors (SSE):  [12.00935939]\n",
      "Training epoch#:  180\n",
      "errors (SSE):  [11.9022016]\n",
      "Training epoch#:  181\n",
      "errors (SSE):  [11.79640624]\n",
      "Training epoch#:  182\n",
      "errors (SSE):  [11.69195259]\n",
      "Training epoch#:  183\n",
      "errors (SSE):  [11.58882031]\n",
      "Training epoch#:  184\n",
      "errors (SSE):  [11.48698948]\n",
      "Training epoch#:  185\n",
      "errors (SSE):  [11.38644054]\n",
      "Training epoch#:  186\n",
      "errors (SSE):  [11.28715433]\n",
      "Training epoch#:  187\n",
      "errors (SSE):  [11.18911202]\n",
      "Training epoch#:  188\n",
      "errors (SSE):  [11.09229515]\n",
      "Training epoch#:  189\n",
      "errors (SSE):  [10.99668562]\n",
      "Training epoch#:  190\n",
      "errors (SSE):  [10.90226564]\n",
      "Training epoch#:  191\n",
      "errors (SSE):  [10.80901775]\n",
      "Training epoch#:  192\n",
      "errors (SSE):  [10.71692482]\n",
      "Training epoch#:  193\n",
      "errors (SSE):  [10.62597002]\n",
      "Training epoch#:  194\n",
      "errors (SSE):  [10.53613682]\n",
      "Training epoch#:  195\n",
      "errors (SSE):  [10.44740898]\n",
      "Training epoch#:  196\n",
      "errors (SSE):  [10.35977054]\n",
      "Training epoch#:  197\n",
      "errors (SSE):  [10.27320583]\n",
      "Training epoch#:  198\n",
      "errors (SSE):  [10.18769944]\n",
      "Training epoch#:  199\n",
      "errors (SSE):  [10.1032362]\n",
      "Training epoch#:  200\n",
      "errors (SSE):  [10.01980123]\n",
      "Training epoch#:  201\n",
      "errors (SSE):  [9.93737987]\n",
      "Training epoch#:  202\n",
      "errors (SSE):  [9.8559577]\n",
      "Training epoch#:  203\n",
      "errors (SSE):  [9.77552056]\n",
      "Training epoch#:  204\n",
      "errors (SSE):  [9.69605447]\n",
      "Training epoch#:  205\n",
      "errors (SSE):  [9.61754571]\n",
      "Training epoch#:  206\n",
      "errors (SSE):  [9.53998077]\n",
      "Training epoch#:  207\n",
      "errors (SSE):  [9.46334634]\n",
      "Training epoch#:  208\n",
      "errors (SSE):  [9.38762931]\n",
      "Training epoch#:  209\n",
      "errors (SSE):  [9.3128168]\n",
      "Training epoch#:  210\n",
      "errors (SSE):  [9.23889608]\n",
      "Training epoch#:  211\n",
      "errors (SSE):  [9.16585465]\n",
      "Training epoch#:  212\n",
      "errors (SSE):  [9.09368019]\n",
      "Training epoch#:  213\n",
      "errors (SSE):  [9.02236054]\n",
      "Training epoch#:  214\n",
      "errors (SSE):  [8.95188375]\n",
      "Training epoch#:  215\n",
      "errors (SSE):  [8.88223803]\n",
      "Training epoch#:  216\n",
      "errors (SSE):  [8.81341176]\n",
      "Training epoch#:  217\n",
      "errors (SSE):  [8.74539349]\n",
      "Training epoch#:  218\n",
      "errors (SSE):  [8.67817195]\n",
      "Training epoch#:  219\n",
      "errors (SSE):  [8.61173602]\n",
      "Training epoch#:  220\n",
      "errors (SSE):  [8.54607475]\n",
      "Training epoch#:  221\n",
      "errors (SSE):  [8.48117732]\n",
      "Training epoch#:  222\n",
      "errors (SSE):  [8.41703311]\n",
      "Training epoch#:  223\n",
      "errors (SSE):  [8.35363161]\n",
      "Training epoch#:  224\n",
      "errors (SSE):  [8.2909625]\n",
      "Training epoch#:  225\n",
      "errors (SSE):  [8.22901556]\n",
      "Training epoch#:  226\n",
      "errors (SSE):  [8.16778076]\n",
      "Training epoch#:  227\n",
      "errors (SSE):  [8.1072482]\n",
      "Training epoch#:  228\n",
      "errors (SSE):  [8.04740811]\n",
      "Training epoch#:  229\n",
      "errors (SSE):  [7.98825087]\n",
      "Training epoch#:  230\n",
      "errors (SSE):  [7.92976699]\n",
      "Training epoch#:  231\n",
      "errors (SSE):  [7.87194713]\n",
      "Training epoch#:  232\n",
      "errors (SSE):  [7.81478208]\n",
      "Training epoch#:  233\n",
      "errors (SSE):  [7.75826275]\n",
      "Training epoch#:  234\n",
      "errors (SSE):  [7.7023802]\n",
      "Training epoch#:  235\n",
      "errors (SSE):  [7.64712559]\n",
      "Training epoch#:  236\n",
      "errors (SSE):  [7.59249025]\n",
      "Training epoch#:  237\n",
      "errors (SSE):  [7.53846559]\n",
      "Training epoch#:  238\n",
      "errors (SSE):  [7.48504318]\n",
      "Training epoch#:  239\n",
      "errors (SSE):  [7.4322147]\n",
      "Training epoch#:  240\n",
      "errors (SSE):  [7.37997194]\n",
      "Training epoch#:  241\n",
      "errors (SSE):  [7.32830683]\n",
      "Training epoch#:  242\n",
      "errors (SSE):  [7.2772114]\n",
      "Training epoch#:  243\n",
      "errors (SSE):  [7.22667781]\n",
      "Training epoch#:  244\n",
      "errors (SSE):  [7.17669832]\n",
      "Training epoch#:  245\n",
      "errors (SSE):  [7.12726533]\n",
      "Training epoch#:  246\n",
      "errors (SSE):  [7.07837132]\n",
      "Training epoch#:  247\n",
      "errors (SSE):  [7.0300089]\n",
      "Training epoch#:  248\n",
      "errors (SSE):  [6.98217079]\n",
      "Training epoch#:  249\n",
      "errors (SSE):  [6.93484981]\n",
      "Training epoch#:  250\n",
      "errors (SSE):  [6.88803889]\n",
      "Training epoch#:  251\n",
      "errors (SSE):  [6.84173107]\n",
      "Training epoch#:  252\n",
      "errors (SSE):  [6.79591947]\n",
      "Training epoch#:  253\n",
      "errors (SSE):  [6.75059735]\n",
      "Training epoch#:  254\n",
      "errors (SSE):  [6.70575804]\n",
      "Training epoch#:  255\n",
      "errors (SSE):  [6.66139498]\n",
      "Training epoch#:  256\n",
      "errors (SSE):  [6.61750171]\n",
      "Training epoch#:  257\n",
      "errors (SSE):  [6.57407186]\n",
      "Training epoch#:  258\n",
      "errors (SSE):  [6.53109917]\n",
      "Training epoch#:  259\n",
      "errors (SSE):  [6.48857746]\n",
      "Training epoch#:  260\n",
      "errors (SSE):  [6.44650065]\n",
      "Training epoch#:  261\n",
      "errors (SSE):  [6.40486273]\n",
      "Training epoch#:  262\n",
      "errors (SSE):  [6.36365782]\n",
      "Training epoch#:  263\n",
      "errors (SSE):  [6.32288009]\n",
      "Training epoch#:  264\n",
      "errors (SSE):  [6.28252383]\n",
      "Training epoch#:  265\n",
      "errors (SSE):  [6.24258338]\n",
      "Training epoch#:  266\n",
      "errors (SSE):  [6.20305319]\n",
      "Training epoch#:  267\n",
      "errors (SSE):  [6.1639278]\n",
      "Training epoch#:  268\n",
      "errors (SSE):  [6.12520181]\n",
      "Training epoch#:  269\n",
      "errors (SSE):  [6.08686991]\n",
      "Training epoch#:  270\n",
      "errors (SSE):  [6.04892688]\n",
      "Training epoch#:  271\n",
      "errors (SSE):  [6.01136756]\n",
      "Training epoch#:  272\n",
      "errors (SSE):  [5.97418688]\n",
      "Training epoch#:  273\n",
      "errors (SSE):  [5.93737985]\n",
      "Training epoch#:  274\n",
      "errors (SSE):  [5.90094155]\n",
      "Training epoch#:  275\n",
      "errors (SSE):  [5.86486711]\n",
      "Training epoch#:  276\n",
      "errors (SSE):  [5.82915179]\n",
      "Training epoch#:  277\n",
      "errors (SSE):  [5.79379086]\n",
      "Training epoch#:  278\n",
      "errors (SSE):  [5.7587797]\n",
      "Training epoch#:  279\n",
      "errors (SSE):  [5.72411374]\n",
      "Training epoch#:  280\n",
      "errors (SSE):  [5.6897885]\n",
      "Training epoch#:  281\n",
      "errors (SSE):  [5.65579954]\n",
      "Training epoch#:  282\n",
      "errors (SSE):  [5.62214251]\n",
      "Training epoch#:  283\n",
      "errors (SSE):  [5.5888131]\n",
      "Training epoch#:  284\n",
      "errors (SSE):  [5.5558071]\n",
      "Training epoch#:  285\n",
      "errors (SSE):  [5.52312033]\n",
      "Training epoch#:  286\n",
      "errors (SSE):  [5.49074869]\n",
      "Training epoch#:  287\n",
      "errors (SSE):  [5.45868813]\n",
      "Training epoch#:  288\n",
      "errors (SSE):  [5.42693467]\n",
      "Training epoch#:  289\n",
      "errors (SSE):  [5.39548439]\n",
      "Training epoch#:  290\n",
      "errors (SSE):  [5.36433342]\n",
      "Training epoch#:  291\n",
      "errors (SSE):  [5.33347795]\n",
      "Training epoch#:  292\n",
      "errors (SSE):  [5.30291424]\n",
      "Training epoch#:  293\n",
      "errors (SSE):  [5.27263858]\n",
      "Training epoch#:  294\n",
      "errors (SSE):  [5.24264734]\n",
      "Training epoch#:  295\n",
      "errors (SSE):  [5.21293693]\n",
      "Training epoch#:  296\n",
      "errors (SSE):  [5.18350382]\n",
      "Training epoch#:  297\n",
      "errors (SSE):  [5.15434452]\n",
      "Training epoch#:  298\n",
      "errors (SSE):  [5.12545561]\n",
      "Training epoch#:  299\n",
      "errors (SSE):  [5.0968337]\n"
     ]
    }
   ],
   "source": [
    "ann_epoch_numbers_list = []\n",
    "epoch_numbers = [1, 10, 100, 200, 300]\n",
    "\n",
    "for epoch_number in epoch_numbers:\n",
    "    print(\"Number of epochs : \", epoch_number)\n",
    "    n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, batch_size, epoch_number)\n",
    "    n.train(mnist_train_list)\n",
    "    ann_epoch_numbers_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_numbers_model_results = []\n",
    "for model in ann_epoch_numbers_list: \n",
    "    correct = 0\n",
    "    model.test(mnist_test_list)\n",
    "    for result in model.results:\n",
    "        if (result[0] == result[1]):\n",
    "                correct += 1\n",
    "        pass\n",
    "    correct = 100 * (correct/len(model.results))\n",
    "    epoch_numbers_model_results.append(correct)\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = epoch_numbers\n",
    "y_pos = numpy.arange(len(objects))\n",
    "performance = epoch_numbers_model_results\n",
    "\n",
    "plt.bar(y_pos, performance, align = 'center', alpha = 0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('epochs')\n",
    "\n",
    "fig_epoch_numbers = plt.gcf()\n",
    "plt.show()\n",
    "fig_epoch_numbers.savefig('../images/ann_epoch_numbers_mnist.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size\n",
    "\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_sizes :  1\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [567.57328644]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [269.85573668]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [190.40726136]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [126.40779472]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [77.46012475]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [55.96152622]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [35.14364815]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [17.84279538]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [11.45234666]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [6.50414226]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [3.77081579]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [2.92099592]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [2.22712959]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [1.71084948]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [1.42373953]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [1.27601358]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [1.10942377]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [0.98582873]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [0.90458442]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [0.83617271]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [0.76749956]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [0.72421418]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [0.68735724]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [0.65876112]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [0.63665824]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [0.62080182]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [0.60439958]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [0.57928773]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [0.55191131]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [0.53225862]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [0.51459055]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [0.50084611]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [0.48910507]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [0.47637944]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [0.46168341]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [0.44869932]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [0.4364273]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [0.42285517]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [0.41135561]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [0.40033995]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [0.38885516]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [0.37837585]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [0.3683272]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [0.3593769]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [0.3492543]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [0.33954239]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [0.33036945]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [0.32181085]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [0.3140282]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [0.30707829]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [0.30069043]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [0.29466575]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [0.28898912]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [0.28357111]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [0.27833395]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [0.27324926]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [0.2685597]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [0.26482513]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [0.26184701]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [0.25794268]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [0.25066167]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [0.24296564]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [0.23743732]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [0.232888]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [0.22877693]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [0.22491343]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [0.22121364]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [0.21763524]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [0.21415933]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [0.21077929]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [0.20749266]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [0.20429391]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [0.20117434]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [0.19818287]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [0.19546713]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [0.19292989]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [0.19032066]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [0.18758497]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [0.1847326]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [0.18188268]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [0.17908945]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [0.17630444]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [0.17350436]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [0.17073482]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [0.16808815]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [0.16558763]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [0.16320537]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [0.16091683]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [0.15870776]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [0.15656959]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [0.15449658]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [0.15248455]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [0.15052986]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [0.14862875]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [0.14677722]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [0.14497135]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [0.14320753]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [0.14148265]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [0.13979419]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [0.13814024]\n",
      "Batch_sizes :  10\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [519.68991434]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [221.51531754]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [145.73042425]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [104.31296773]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [77.0413997]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [56.64847892]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [42.29116128]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [33.09143282]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [26.79207645]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [22.12353659]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [18.56398089]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [15.71227863]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [13.4093346]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [11.62337196]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [10.14400107]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [8.91693705]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [7.90444777]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [7.07172414]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [6.37496298]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [5.77914868]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [5.2699439]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [4.83472482]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [4.45890761]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [4.12803549]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [3.83361067]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [3.57225565]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [3.34109637]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [3.13564744]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [2.95175944]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [2.78777082]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [2.64059512]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [2.50742106]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [2.3864039]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [2.27541658]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [2.17194831]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [2.07619702]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [1.98890119]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [1.90901758]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [1.8353452]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [1.76707019]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [1.70362429]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [1.64453606]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [1.58936025]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [1.53762841]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [1.48878613]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [1.44222928]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [1.39785642]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [1.35648209]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [1.31840569]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [1.28288495]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [1.24918275]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [1.21688684]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [1.18571026]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [1.15536422]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [1.12552714]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [1.09581055]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [1.06589983]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [1.0363245]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [1.00839382]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [0.98251109]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [0.95817914]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [0.93493629]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [0.91270564]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [0.89150351]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [0.87109222]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [0.85137921]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [0.83278592]\n",
      "Training epoch#:  67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [0.8156231]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [0.79976988]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [0.78488836]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [0.77063317]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [0.75672121]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [0.74295361]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [0.72925004]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [0.71567914]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [0.70245048]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [0.68983209]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [0.67798897]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [0.66692541]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [0.65655389]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [0.64676988]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [0.63748701]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [0.62864377]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [0.62019846]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [0.61211663]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [0.60436021]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [0.59688586]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [0.5896427]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [0.58257144]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [0.5756107]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [0.56870416]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [0.56180493]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [0.55488206]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [0.54793547]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [0.54099904]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [0.53406593]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [0.52701]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [0.51970081]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [0.51213746]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [0.50442136]\n",
      "Batch_sizes :  100\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [1283.73980323]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [599.23282492]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [349.69216207]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [267.79382176]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [232.40790991]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [208.48053766]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [189.5792829]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [174.31049798]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [162.16749135]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [152.49358169]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [144.574563]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [137.79417615]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [131.7521185]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [126.22595732]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [121.0922465]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [116.2984751]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [111.81854612]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [107.62147307]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [103.67587249]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [99.95778551]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [96.44818904]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [93.12908837]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [89.98424276]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [87.00049649]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [84.16722598]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [81.47585376]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [78.92113697]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [76.50175156]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [74.21682801]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [72.0612447]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [70.0242755]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [68.09225321]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [66.25203657]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [64.49217178]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [62.80223867]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [61.1722069]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [59.59385676]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [58.06604828]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [56.59680794]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [55.19408877]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [53.85671819]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [52.57662586]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [51.34494002]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [50.15538541]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [49.00507168]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [47.8937081]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [46.82174181]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [45.7884254]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [44.79130577]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [43.82737386]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [42.89443935]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [41.99130803]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [41.11693941]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [40.26985507]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [39.44832918]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [38.65083864]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [37.87619117]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [37.1232806]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [36.39076437]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [35.67685593]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [34.97928127]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [34.29554496]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [33.62367905]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [32.96322199]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [32.31559159]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [31.68327926]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [31.06845229]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [30.47206287]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [29.89383079]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [29.33269951]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [28.78728882]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [28.25614527]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [27.73787496]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [27.23135218]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [26.73600392]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [26.25191427]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [25.77959219]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [25.31957675]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [24.87214633]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [24.43721731]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [24.01436784]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [23.60291355]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [23.20200469]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [22.8107363]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [22.4282585]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [22.05386198]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [21.68701436]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [21.32734613]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [20.97461154]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [20.62865404]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [20.28938479]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [19.95676654]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [19.63079464]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [19.31147551]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [18.99880698]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [18.69276464]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [18.39329505]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [18.10031469]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [17.81371217]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [17.53335176]\n",
      "Batch_sizes :  200\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [1551.51760115]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [770.90400372]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [598.97485566]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [471.4493409]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [353.88597169]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [302.16626529]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [269.32825294]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [248.11631412]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [230.52930583]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [216.57943852]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [204.70121556]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [194.7685035]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [186.26036149]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [178.94999926]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [172.50050651]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [166.74320332]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [161.53102117]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [156.72293681]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [152.39775]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [148.25034495]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [144.96187944]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [141.65385149]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [140.70833022]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [138.35695746]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [136.72756679]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [132.73141599]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [127.70696835]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [123.96658937]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [121.01941464]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [117.71181361]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [115.45339969]\n",
      "Training epoch#:  31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [112.50381739]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [110.58405262]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [107.9121009]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [106.17649946]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [103.73971073]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [102.11532975]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [99.90474368]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [98.3616867]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [96.37714331]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [94.90180143]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [93.13199774]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [91.71495435]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [90.13394248]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [88.7717334]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [87.34357911]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [86.03890913]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [84.72646572]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [83.4831034]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [82.25709486]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [81.07517604]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [79.91743008]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [78.79335388]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [77.69351308]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [76.62184351]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [75.57271977]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [74.54756121]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [73.5428418]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [72.55853775]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [71.59248853]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [70.64404994]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [69.71194076]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [68.79553622]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [67.89422955]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [67.0077955]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [66.13620568]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [65.27964538]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [64.43839459]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [63.61275014]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [62.80294229]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [62.00908192]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [61.23113239]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [60.46890791]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [59.72209052]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [58.99025763]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [58.27291256]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [57.5695135]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [56.87949846]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [56.20230441]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [55.53737903]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [54.88418376]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [54.24218836]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [53.61085952]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [52.98964984]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [52.37799872]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [51.7753606]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [51.18127368]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [50.59546573]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [50.01796295]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [49.44913968]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [48.88965341]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [48.34026765]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [47.80163753]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [47.27415313]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [46.75788789]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [46.25263565]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [45.75799022]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [45.27342788]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [44.79837292]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [44.33224232]\n",
      "Batch_sizes :  1000\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [5330.38222155]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [1452.19271192]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [947.79294835]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [932.74741732]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [951.27773238]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [918.45522451]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [956.31108974]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [916.19247089]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [942.36163616]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [882.17121464]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [820.03187421]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [785.75539577]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [691.88285003]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [658.35163918]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [654.15461392]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [645.89776938]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [624.98222926]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [561.98108303]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [494.01618368]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [469.53773704]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [433.75922726]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [420.93411676]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [417.73181154]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [369.91066968]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [350.53417627]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [340.74471133]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [351.0397439]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [320.07845938]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [320.60706004]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [322.39347564]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [336.27311058]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [313.58820346]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [315.00303198]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [319.54378832]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [326.13382595]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [308.01809565]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [301.75883837]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [301.94932247]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [300.18203302]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [282.49603606]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [275.96292614]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [273.43609258]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [271.42526669]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [266.00562776]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [261.26659037]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [257.2801607]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [253.57262773]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [248.92719625]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [246.02374054]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [241.35197267]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [239.09670428]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [234.49147541]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [232.7169706]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [228.25130287]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [226.82322968]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [222.54056974]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [221.35501474]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [217.28061579]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [216.25747231]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [212.40627744]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [211.48325987]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [207.86491589]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [206.99269644]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [203.61471461]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [202.75308475]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [199.62277693]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [198.73768727]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [195.8632117]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [194.92459184]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [192.31531153]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [191.29561807]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [188.96194723]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [187.83540973]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [185.78833135]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [184.53084042]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [182.78127094]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [181.37077632]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [179.92891272]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [178.34611034]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [177.22082921]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [175.449878]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [174.64818982]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [172.6772449]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [172.20376274]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [170.02522324]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [169.88160253]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [167.49209562]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [167.67644076]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [165.0766454]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [165.58293457]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [162.77736435]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [163.59498736]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [160.59181023]\n",
      "Training epoch#:  93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [161.70532863]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [158.51623179]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [159.90545285]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [156.5454963]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [158.18590457]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [154.67327424]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [156.53679429]\n"
     ]
    }
   ],
   "source": [
    "ann_batch_sizes_list = []\n",
    "batch_sizes = [1, 10, 100, 200, len(mnist_train_list)]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"Batch_sizes : \", batch_size)\n",
    "    n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, batch_size, epochs)\n",
    "    n.train(mnist_train_list)\n",
    "    ann_batch_sizes_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes_model_results = []\n",
    "for model in ann_batch_sizes_list: \n",
    "    correct = 0\n",
    "    model.test(mnist_test_list)\n",
    "    for result in model.results:\n",
    "        if (result[0] == result[1]):\n",
    "                correct += 1\n",
    "        pass\n",
    "    correct = 100 * (correct/len(model.results))\n",
    "    batch_sizes_model_results.append(correct)\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = batch_sizes\n",
    "y_pos = numpy.arange(len(objects))\n",
    "performance = batch_sizes_model_results\n",
    "\n",
    "plt.bar(y_pos, performance, align = 'center', alpha = 0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('batch_size')\n",
    "\n",
    "fig_batch_sizes = plt.gcf()\n",
    "plt.show()\n",
    "fig_batch_sizes.savefig('../images/ann_batch_sizes_mnist.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rates :  0.01\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [2604.90027511]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [1211.81768303]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [939.50484057]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [864.74277469]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [820.99068921]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [786.5484068]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [756.82903343]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [730.35018158]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [706.25156508]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [684.00035175]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [663.31996419]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [644.06805635]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [626.14824207]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [609.47255278]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [593.95178487]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [579.49595012]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [566.01696923]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [553.43102036]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [541.65999724]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [530.63217629]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [520.28232914]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [510.5514942]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [501.38656317]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [492.73978461]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [484.56824712]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [476.83337758]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [469.50047264]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [462.53827169]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [455.91857323]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [449.61589335]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [443.60716347]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [437.87146365]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [432.38978773]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [427.14483663]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [422.12083639]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [417.30337796]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [412.67927585]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [408.23644352]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [403.96378307]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [399.85108766]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [395.888955]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [392.06871044]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [388.38233859]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [384.82242234]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [381.38208845]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [378.05495881]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [374.8351069]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [371.71701859]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [368.69555696]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [365.76593063]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [362.92366521]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [360.16457743]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [357.48475187]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [354.88051977]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [352.34843988]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [349.88528096]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [347.488006]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [345.15375771]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [342.87984539]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [340.66373283]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [338.50302734]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [336.39546966]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [334.33892468]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [332.33137302]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [330.37090314]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [328.45570423]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [326.58405958]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [324.75434049]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [322.96500062]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [321.21457083]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [319.50165434]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [317.8249223]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [316.18310965]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [314.57501129]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [312.99947858]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [311.45541594]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [309.94177788]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [308.45756608]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [307.00182675]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [305.57364813]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [304.17215819]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [302.79652245]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [301.44594198]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [300.11965148]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [298.81691751]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [297.53703683]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [296.27933489]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [295.04316427]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [293.82790342]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [292.63295527]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [291.45774611]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [290.30172438]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [289.16435962]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [288.04514147]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [286.94357871]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [285.85919836]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [284.79154483]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [283.7401791]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [282.70467802]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [281.68463354]\n",
      "Learning_rates :  0.1\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [1338.96504916]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [628.45703456]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [502.4623356]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [434.63206793]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [392.09492645]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [362.34728121]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [339.94964526]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [322.21433517]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [307.66094259]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [295.40122842]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [284.86562012]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [275.66912228]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [267.5401108]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [260.28005737]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [253.73955491]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [247.80340641]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [242.3809793]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [237.39974171]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [232.80079432]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [228.53569883]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [224.56417608]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [220.85240362]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [217.37173592]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [214.09772795]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [211.00937937]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [208.08854172]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [205.319447]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [202.68832826]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [200.18311066]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [197.79315769]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [195.50906088]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [193.32246475]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [191.22592024]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [189.21276177]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [187.27700377]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [185.41325331]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [183.61663632]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [181.88273485]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [180.20753373]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [178.58737482]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [177.01891776]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [175.49910589]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [174.02513671]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [172.59443601]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [171.20463503]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [169.85355038]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [168.53916615]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [167.25961793]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [166.01317863]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [164.79824563]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [163.61332942]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [162.45704318]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [161.32809362]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [160.22527262]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [159.14744971]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [158.09356541]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [157.0626251]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [156.05369364]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [155.06589048]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [154.09838525]\n",
      "Training epoch#:  60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [153.15039387]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [152.22117496]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [151.31002671]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [150.41628398]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [149.53931575]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [148.67852276]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [147.83333545]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [147.003212]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [146.18763664]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [145.38611804]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [144.59818789]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [143.82339955]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [143.06132684]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [142.31156292]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [141.57371924]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [140.84742458]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [140.13232412]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [139.42807864]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [138.73436368]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [138.05086883]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [137.377297]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [136.71336378]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [136.05879679]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [135.4133351]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [134.77672866]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [134.14873776]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [133.52913252]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [132.91769239]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [132.31420572]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [131.71846927]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [131.13028783]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [130.54947383]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [129.97584688]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [129.40923351]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [128.84946676]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [128.29638588]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [127.74983599]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [127.20966784]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [126.67573747]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [126.14790598]\n",
      "Learning_rates :  0.2\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [1077.18925163]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [474.30108902]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [375.24913695]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [326.04762434]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [295.35923308]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [273.75182028]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [257.30440014]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [244.13250636]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [233.22342001]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [223.97380094]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [215.99212597]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [209.00744932]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [202.82329835]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [197.2923653]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [192.30152649]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [187.76235591]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [183.60477297]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [179.77260374]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [176.22038236]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [172.91099432]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [169.81391036]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [166.90384405]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [164.15971768]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [161.5638544]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [159.10133832]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [156.75950095]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [154.52750517]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [152.39600642]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [150.35687741]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [148.40298566]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [146.52801562]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [144.72632792]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [142.99284901]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [141.32298506]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [139.71255482]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [138.1577368]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [136.65502724]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [135.20120598]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [133.79330814]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [132.42860018]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [131.1045592]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [129.81885466]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [128.56933221]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [127.35399909]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [126.17101091]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [125.01865959]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [123.89536236]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [122.79965164]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [121.7301658]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [120.68564053]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [119.66490105]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [118.66685477]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [117.69048459]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [116.73484277]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [115.79904517]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [114.88226605]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [113.98373328]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [113.10272396]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [112.2385604]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [111.3906065]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [110.55826444]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [109.74097174]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [108.93819848]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [108.14944495]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [107.37423934]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [106.61213581]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [105.86271257]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [105.12557023]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [104.40033023]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [103.68663335]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [102.98413838]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [102.29252082]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [101.61147165]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [100.94069626]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [100.27991328]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [99.62885365]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [98.98725965]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [98.35488404]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [97.73148923]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [97.11684659]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [96.51073574]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [95.91294401]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [95.32326585]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [94.74150241]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [94.16746112]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [93.60095533]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [93.04180403]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [92.48983157]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [91.94486744]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [91.40674607]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [90.87530671]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [90.35039324]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [89.83185405]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [89.31954194]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [88.81331401]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [88.31303155]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [87.81855995]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [87.32976862]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [86.84653085]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [86.36872378]\n",
      "Learning_rates :  0.4\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [1268.68033594]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [512.68869703]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [359.25676206]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [339.34374097]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [287.73746587]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [249.90940818]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [227.73533922]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [211.25667745]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [198.2503725]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [187.69714761]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [178.93899302]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [171.50326605]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [165.0574589]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [159.37376068]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [154.29530324]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [149.71060079]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [145.53700976]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [141.71081497]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [138.18142246]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [134.90788997]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [131.85672343]\n",
      "Training epoch#:  21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [129.00034733]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [126.31594953]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [123.78456111]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [121.39030802]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [119.11980206]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [116.9616488]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [114.90605358]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [112.94450823]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [111.06954386]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [109.27453707]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [107.55355945]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [105.90126184]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [104.31278623]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [102.78369921]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [101.30994184]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [99.88779135]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [98.51383128]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [97.18492716]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [95.89820568]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [94.6510359]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [93.44101165]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [92.26593446]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [91.123797]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [90.01276671]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [88.93117007]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [87.87747732]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [86.85028805]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [85.84831765]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [84.87038483]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [83.91540028]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [82.98235641]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [82.0703183]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [81.17841568]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [80.30583599]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [79.45181836]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [78.61564843]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [77.79665396]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [76.99420104]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [76.20769087]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [75.43655693]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [74.68026255]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [73.93829871]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [73.21018195]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [72.49545253]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [71.79367244]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [71.10442359]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [70.4273059]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [69.76193533]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [69.10794193]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [68.46496797]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [67.83266616]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [67.21069812]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [66.59873338]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [65.99644897]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [65.40352991]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [64.81967069]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [64.24457776]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [63.67797289]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [63.11959707]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [62.56921417]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [62.02661389]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [61.49161319]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [60.96405562]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [60.44380859]\n",
      "Training epoch#:  85\n",
      "errors (SSE):  [59.93075858]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [59.42480505]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [58.92585379]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [58.43381043]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [57.94857502]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [57.47003796]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [56.99807754]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [56.53255906]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [56.07333525]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [55.62024777]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [55.17312942]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [54.73180671]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [54.29610269]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [53.86583977]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [53.44084242]\n",
      "Learning_rates :  0.8\n",
      "Training epoch#:  0\n",
      "errors (SSE):  [1407.69688287]\n",
      "Training epoch#:  1\n",
      "errors (SSE):  [714.1138196]\n",
      "Training epoch#:  2\n",
      "errors (SSE):  [538.64077112]\n",
      "Training epoch#:  3\n",
      "errors (SSE):  [360.93654693]\n",
      "Training epoch#:  4\n",
      "errors (SSE):  [313.49352791]\n",
      "Training epoch#:  5\n",
      "errors (SSE):  [283.78458653]\n",
      "Training epoch#:  6\n",
      "errors (SSE):  [255.44892116]\n",
      "Training epoch#:  7\n",
      "errors (SSE):  [230.11705329]\n",
      "Training epoch#:  8\n",
      "errors (SSE):  [212.31350608]\n",
      "Training epoch#:  9\n",
      "errors (SSE):  [197.49818529]\n",
      "Training epoch#:  10\n",
      "errors (SSE):  [185.04083267]\n",
      "Training epoch#:  11\n",
      "errors (SSE):  [174.4809916]\n",
      "Training epoch#:  12\n",
      "errors (SSE):  [165.51292896]\n",
      "Training epoch#:  13\n",
      "errors (SSE):  [157.85762204]\n",
      "Training epoch#:  14\n",
      "errors (SSE):  [151.2550516]\n",
      "Training epoch#:  15\n",
      "errors (SSE):  [145.48564737]\n",
      "Training epoch#:  16\n",
      "errors (SSE):  [140.37802621]\n",
      "Training epoch#:  17\n",
      "errors (SSE):  [135.80107442]\n",
      "Training epoch#:  18\n",
      "errors (SSE):  [131.65359115]\n",
      "Training epoch#:  19\n",
      "errors (SSE):  [127.85801237]\n",
      "Training epoch#:  20\n",
      "errors (SSE):  [124.35657424]\n",
      "Training epoch#:  21\n",
      "errors (SSE):  [121.10696685]\n",
      "Training epoch#:  22\n",
      "errors (SSE):  [118.0772679]\n",
      "Training epoch#:  23\n",
      "errors (SSE):  [115.24190552]\n",
      "Training epoch#:  24\n",
      "errors (SSE):  [112.57935821]\n",
      "Training epoch#:  25\n",
      "errors (SSE):  [110.0705865]\n",
      "Training epoch#:  26\n",
      "errors (SSE):  [107.69745071]\n",
      "Training epoch#:  27\n",
      "errors (SSE):  [105.44170473]\n",
      "Training epoch#:  28\n",
      "errors (SSE):  [103.28560752]\n",
      "Training epoch#:  29\n",
      "errors (SSE):  [101.21406448]\n",
      "Training epoch#:  30\n",
      "errors (SSE):  [99.2166883]\n",
      "Training epoch#:  31\n",
      "errors (SSE):  [97.2881265]\n",
      "Training epoch#:  32\n",
      "errors (SSE):  [95.42653181]\n",
      "Training epoch#:  33\n",
      "errors (SSE):  [93.63136089]\n",
      "Training epoch#:  34\n",
      "errors (SSE):  [91.90166859]\n",
      "Training epoch#:  35\n",
      "errors (SSE):  [90.23534207]\n",
      "Training epoch#:  36\n",
      "errors (SSE):  [88.62915616]\n",
      "Training epoch#:  37\n",
      "errors (SSE):  [87.07929566]\n",
      "Training epoch#:  38\n",
      "errors (SSE):  [85.58197263]\n",
      "Training epoch#:  39\n",
      "errors (SSE):  [84.13388815]\n",
      "Training epoch#:  40\n",
      "errors (SSE):  [82.73244383]\n",
      "Training epoch#:  41\n",
      "errors (SSE):  [81.37570164]\n",
      "Training epoch#:  42\n",
      "errors (SSE):  [80.06213913]\n",
      "Training epoch#:  43\n",
      "errors (SSE):  [78.79030497]\n",
      "Training epoch#:  44\n",
      "errors (SSE):  [77.55851224]\n",
      "Training epoch#:  45\n",
      "errors (SSE):  [76.36466404]\n",
      "Training epoch#:  46\n",
      "errors (SSE):  [75.20621966]\n",
      "Training epoch#:  47\n",
      "errors (SSE):  [74.08024987]\n",
      "Training epoch#:  48\n",
      "errors (SSE):  [72.98352157]\n",
      "Training epoch#:  49\n",
      "errors (SSE):  [71.91257632]\n",
      "Training epoch#:  50\n",
      "errors (SSE):  [70.86379811]\n",
      "Training epoch#:  51\n",
      "errors (SSE):  [69.83348974]\n",
      "Training epoch#:  52\n",
      "errors (SSE):  [68.81799833]\n",
      "Training epoch#:  53\n",
      "errors (SSE):  [67.8139516]\n",
      "Training epoch#:  54\n",
      "errors (SSE):  [66.81866929]\n",
      "Training epoch#:  55\n",
      "errors (SSE):  [65.83073916]\n",
      "Training epoch#:  56\n",
      "errors (SSE):  [64.85054001]\n",
      "Training epoch#:  57\n",
      "errors (SSE):  [63.88027922]\n",
      "Training epoch#:  58\n",
      "errors (SSE):  [62.92329287]\n",
      "Training epoch#:  59\n",
      "errors (SSE):  [61.9829606]\n",
      "Training epoch#:  60\n",
      "errors (SSE):  [61.06185866]\n",
      "Training epoch#:  61\n",
      "errors (SSE):  [60.16142398]\n",
      "Training epoch#:  62\n",
      "errors (SSE):  [59.28201873]\n",
      "Training epoch#:  63\n",
      "errors (SSE):  [58.42319257]\n",
      "Training epoch#:  64\n",
      "errors (SSE):  [57.58399358]\n",
      "Training epoch#:  65\n",
      "errors (SSE):  [56.76324559]\n",
      "Training epoch#:  66\n",
      "errors (SSE):  [55.95975704]\n",
      "Training epoch#:  67\n",
      "errors (SSE):  [55.17245479]\n",
      "Training epoch#:  68\n",
      "errors (SSE):  [54.40044927]\n",
      "Training epoch#:  69\n",
      "errors (SSE):  [53.6430432]\n",
      "Training epoch#:  70\n",
      "errors (SSE):  [52.8996996]\n",
      "Training epoch#:  71\n",
      "errors (SSE):  [52.1699869]\n",
      "Training epoch#:  72\n",
      "errors (SSE):  [51.45351906]\n",
      "Training epoch#:  73\n",
      "errors (SSE):  [50.74990627]\n",
      "Training epoch#:  74\n",
      "errors (SSE):  [50.05872495]\n",
      "Training epoch#:  75\n",
      "errors (SSE):  [49.37950853]\n",
      "Training epoch#:  76\n",
      "errors (SSE):  [48.71175399]\n",
      "Training epoch#:  77\n",
      "errors (SSE):  [48.0549362]\n",
      "Training epoch#:  78\n",
      "errors (SSE):  [47.40852325]\n",
      "Training epoch#:  79\n",
      "errors (SSE):  [46.77198848]\n",
      "Training epoch#:  80\n",
      "errors (SSE):  [46.1448187]\n",
      "Training epoch#:  81\n",
      "errors (SSE):  [45.52652017]\n",
      "Training epoch#:  82\n",
      "errors (SSE):  [44.91662529]\n",
      "Training epoch#:  83\n",
      "errors (SSE):  [44.31470233]\n",
      "Training epoch#:  84\n",
      "errors (SSE):  [43.72036853]\n",
      "Training epoch#:  85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors (SSE):  [43.1333055]\n",
      "Training epoch#:  86\n",
      "errors (SSE):  [42.55327477]\n",
      "Training epoch#:  87\n",
      "errors (SSE):  [41.98013139]\n",
      "Training epoch#:  88\n",
      "errors (SSE):  [41.41383441]\n",
      "Training epoch#:  89\n",
      "errors (SSE):  [40.85445282]\n",
      "Training epoch#:  90\n",
      "errors (SSE):  [40.30216469]\n",
      "Training epoch#:  91\n",
      "errors (SSE):  [39.75724701]\n",
      "Training epoch#:  92\n",
      "errors (SSE):  [39.22005456]\n",
      "Training epoch#:  93\n",
      "errors (SSE):  [38.69098833]\n",
      "Training epoch#:  94\n",
      "errors (SSE):  [38.17045715]\n",
      "Training epoch#:  95\n",
      "errors (SSE):  [37.65883834]\n",
      "Training epoch#:  96\n",
      "errors (SSE):  [37.15644367]\n",
      "Training epoch#:  97\n",
      "errors (SSE):  [36.66349567]\n",
      "Training epoch#:  98\n",
      "errors (SSE):  [36.1801165]\n",
      "Training epoch#:  99\n",
      "errors (SSE):  [35.70632899]\n"
     ]
    }
   ],
   "source": [
    "ann_learning_rates_list = []\n",
    "learning_rates = [0.01, 0.1, 0.2, 0.4, 0.8]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"Learning_rates : \", learning_rate)\n",
    "    n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, batch_size, epochs)\n",
    "    n.train(mnist_train_list)\n",
    "    ann_learning_rates_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates_model_results = []\n",
    "for model in ann_learning_rates_list: \n",
    "    correct = 0\n",
    "    model.test(mnist_test_list)\n",
    "    for result in model.results:\n",
    "        if (result[0] == result[1]):\n",
    "                correct += 1\n",
    "        pass\n",
    "    correct = 100 * (correct/len(model.results))\n",
    "    learning_rates_model_results.append(correct)\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = learning_rates\n",
    "y_pos = numpy.arange(len(objects))\n",
    "performance = learning_rates_model_results\n",
    "\n",
    "plt.bar(y_pos, performance, align = 'center', alpha = 0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('learning_rate')\n",
    "\n",
    "fig_learning_rates = plt.gcf()\n",
    "plt.show()\n",
    "fig_learning_rates.savefig('../images/ann_learning_rates_mnist.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Red and White Wine Quality EDA\" dataset\n",
    "\n",
    "### Loading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set size:  4899\n"
     ]
    }
   ],
   "source": [
    "wine_quality_file = open(\"../datasets/winequality-white.csv\", 'r')\n",
    "wine_quality_list = wine_quality_file.readlines()\n",
    "wine_quality_file.close()\n",
    "\n",
    "print(\"set size: \", len(wine_quality_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6\n",
      "\n",
      "7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine_quality_list[1])\n",
    "\"\"\"\n",
    "for entry in wine_quality_list:\n",
    "    entry = entry\n",
    "\"\"\"\n",
    "print(wine_quality_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into *training set* and *testing set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size:  3919\n",
      "test set size:  980\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(wine_quality_list)\n",
    "\n",
    "wine_quality_train_list = wine_quality_list[:int(len(wine_quality_list) * .8)]\n",
    "print(\"train set size: \", len(wine_quality_train_list))\n",
    "\n",
    "wine_quality_test_list = wine_quality_list[int(len(wine_quality_list) * .8):] # why does it work ? should be 0.2 ! is there something I missed ? it's been 5 years I haven't used Python, mais quand mme faut pas abuser...\n",
    "print(\"test set size: \", len(wine_quality_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs\n",
    "\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs :  1\n",
      "Training epoch#:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '7.1;0.18;0.74;15.6;0.044;44;176;0.9996;3.38;0.67;9;6\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-af613114af52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of epochs : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwine_quality_train_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mann_epoch_numbers_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-eb599290bfc5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_inputs)\u001b[0m\n\u001b[0;32m    124\u001b[0m                                         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.01\u001b[0m \u001b[1;31m#all initialised to 0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                                         \u001b[1;31m#all_value[0] has the target class label for this instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                                         \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                                         \u001b[1;31m#convert  inputs list to 2d array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '7.1;0.18;0.74;15.6;0.044;44;176;0.9996;3.38;0.67;9;6\\n'"
     ]
    }
   ],
   "source": [
    "ann_epoch_numbers_list = []\n",
    "epoch_numbers = [1, 10, 100, 200, 300]\n",
    "\n",
    "for epoch_number in epoch_numbers:\n",
    "    print(\"Number of epochs : \", epoch_number)\n",
    "    n = neuralNetwork(input_nodes = 11, hidden_nodes, output_nodes = 2, learning_rate, batch_size, epoch_number)\n",
    "    n.train(wine_quality_train_list)\n",
    "    ann_epoch_numbers_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy% =  89.8\n"
     ]
    }
   ],
   "source": [
    "epoch_numbers_model_results = []\n",
    "for model in ann_epoch_numbers_list: \n",
    "    correct = 0\n",
    "    model.test(mnist_test_list)\n",
    "    for result in model.results:\n",
    "        if (result[0] == result[1]):\n",
    "                correct += 1\n",
    "        pass\n",
    "    correct = 100 * (correct/len(model.results))\n",
    "    epoch_numbers_model_results.append(correct)\n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the accuracy of the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ann in n_list:\n",
    "    print(\"Number of epochs : \", ann.ep)\n",
    "    plt.figure(figsize = (20,5))\n",
    "    plt.plot(range(0, ann.ep), numpy.asfarray(ann.E), marker = 'o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Number of updates')\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../images/ann_e' + ann.ep + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size\n",
    "\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = []\n",
    "batch_sizes = [10, 20, 50, 80, 160]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"Batch_sizes : \", batch_size)\n",
    "    n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, batch_size, epoch_size)\n",
    "    n.train(mnist_train_list)\n",
    "    n_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the model error for each batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in n_list:\n",
    "    print(\"Batch sizes : \", ann.batch_size)\n",
    "    plt.figure(figsize = (20,5))\n",
    "    plt.plot(range(0, ann.ep), numpy.asfarray(ann.E), marker = 'o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Number of updates')\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../images/ann_b' + ann.batch_size + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the ANNs and compute their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in n_list:\n",
    "    ann.test(mnist_test_list)\n",
    "    correct = 0\n",
    "\n",
    "    for result in ann.results:\n",
    "        if (result[0] == result[1]):\n",
    "                correct += 1\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "    print (\"Batch sizes : \", ann.batch_size, \", test set accuracy% = \", (100 * correct / len(ann.results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = []\n",
    "learning_rates = [0.01, 0.1, 0.2, 0.4, 0.8]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"Learning_rates : \", learning_rate)\n",
    "    n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, batch_size, epoch_size)\n",
    "    n.train(mnist_train_list)\n",
    "    n_list.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the model error for each batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in n_list:\n",
    "    print(\"Learning_rate : \", ann.lr)\n",
    "    plt.figure(figsize = (20,5))\n",
    "    plt.plot(range(0, ann.ep), numpy.asfarray(ann.E), marker = 'o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Number of updates')\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../images/ann_l' + ann.learning_rate + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the ANNs and compute their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
